Image Classification Using MobileNetV2
This project trains an image classification model using a pretrained MobileNetV2 network in TensorFlow/Keras.
Transfer learning is used to improve performance compared to training a model from scratch.

Dataset
The dataset consists of:

A CSV file containing image IDs and labels
Images organized into folders by class label
The CSV file must include the following columns:

id – image filename
label – class name (folder name)
Requirements
Python 3.x
TensorFlow
NumPy
Pandas
scikit-learn
How to Run
Open the Python script.
Add your file locations for:
CSV_PATH (path to Dataset.csv)
IMG_DIR (path to the image folders)
Run the script:
Model
Base model: MobileNetV2 (pretrained on ImageNet)
Base model is frozen
Custom classification head with:
Global Average Pooling
Dense layer
Dropout
Softmax output
Training
Image size: 128 × 128
Batch size: 8
Epochs: 70
Optimizer: Adam
Loss function: Categorical Crossentropy
Evaluation
The model is evaluated on a test set using:

Accuracy
Precision
Recall
F1-score
Confusion matrix
Notes / Results
Several experiments were performed to improve model performance.

A CNN trained from scratch achieved low accuracy (~18%), even after multiple epochs.
Switching to a pretrained MobileNetV2 model improved performance to ~30% accuracy.
Further tuning (reducing batch size and increasing epochs) significantly improved results.
Final training setup:

Batch size: 8
Epochs: 70
Final results:

Training accuracy: ~82%
Best validation accuracy: ~48%
Test accuracy: ~42.8%
Precision: ~47.2%
Recall: ~42.8%
F1-score: ~42.0%
These results show that transfer learning with MobileNetV2 greatly improved performance compared to training a CNN from scratch, though validation accuracy suggests some overfitting remains.
